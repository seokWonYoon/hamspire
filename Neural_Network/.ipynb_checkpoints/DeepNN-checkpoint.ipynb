{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 은닉층(신경망층)을 둘이상을 구성한 심층신경망이 곧 딥러닝. 다층신경망(심층신경망)을 만드는 작업은 단일 신경망에 가중치와 편향을 추가하기만 하면 됨. 입력층과 출력층은 각각 feature와 분류갯수로 맞추고 중간의 연결부분은 맞닿은 층의 뉴런수와 같도록 맞추면 됨. 중간의 연결부분을 은닉층이라고하며 은닉층의 뉴런수는 하이퍼파라미터이니 실험을 통해 가장 적절한 수를 정하면 됨. 따라서 아래의10은 뉴런수를 증가시키면서 100%에 도달하여 얻은 결과임\n",
    "##### AdamOptimizer 를 최적화 함수로 사용하였으며, 이는 앞서 사용한 GradientDescentOptimizer보다 보편적으로 성능이 좋은 평가임. 즉 필요한 함수를 개인이 사용하는 것도 성능을 끌어올리는 요건이 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array(\n",
    "    [[0,0],\n",
    "     [1,0],\n",
    "     [1,1],\n",
    "     [0,0],\n",
    "     [0,0],\n",
    "     [0,1]])\n",
    "# [기타, 포유류, 조류]\n",
    "\n",
    "y_data = np.array([\n",
    "    [1,0,0], # 기타\n",
    "    [0,1,0], # 포유류\n",
    "    [0,0,1], # 조류\n",
    "    [1,0,0],\n",
    "    [1,0,0],\n",
    "    [0,0,1]\n",
    "    ])\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **********\n",
    "# 신경망 모델 구성\n",
    "# **********\n",
    "\n",
    "# 첫번째 가중치 차원을 [특성, 히든레이어 뉴런갯수] -> [2,10] \n",
    "W1 = tf.Variable(tf.random_uniform([2,10], -1, 1.))\n",
    "# 두번째 가중치 차원을 [히든레이어 뉴런갯수,분류갯수] -> [10,3] \n",
    "W2 = tf.Variable(tf.random_uniform([10,3], -1, 1.))\n",
    "\n",
    "# 편향을 각 레이어 아웃풋 갯수\n",
    "# b1 은 히든레이어 뉴런 갯수 10\n",
    "# b2 는 최종결과물인 분류 갯수 3\n",
    "b1 = tf.Variable(tf.zeros([10]))\n",
    "b2 = tf.Variable(tf.zeros([3]))\n",
    "#신경망의 히든레이어에 가중치 W1 과 편향b1 을 적용\n",
    "L1 = tf.add(tf.matmul(X, W1), b1)\n",
    "L1 = tf.nn.relu(L1)\n",
    "# 최종 아웃풋 계산\n",
    "# 히든레이어에 W2 와 b2 를 적용하여 3개의 출력값 생성\n",
    "model = tf.add(tf.matmul(L1, W2), b2)\n",
    "\n",
    "# 텐서플로우 cross_entropy 함수를 이용하여 softmax 계산\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=model))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 1.1279551\n",
      "20 0.96935654\n",
      "30 0.85682106\n",
      "40 0.75982827\n",
      "50 0.6712351\n",
      "60 0.591836\n",
      "70 0.51755047\n",
      "80 0.4488865\n",
      "90 0.38677207\n",
      "100 0.33107227\n"
     ]
    }
   ],
   "source": [
    "# **********\n",
    "# 신경망 모델 학습\n",
    "# **********\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(100):\n",
    "    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    if(step + 1) % 10 == 0:\n",
    "        print(step +1, sess.run(cost, feed_dict={X: x_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값:  [0 1 2 0 0 2]\n",
      "실제값:  [0 1 2 0 0 2]\n",
      "정확도: 100.00\n"
     ]
    }
   ],
   "source": [
    "# *****\n",
    "# 결과 확인\n",
    "# 0 : 기타, 1: 포유류, 2: 조류\n",
    "# *****\n",
    "\n",
    "prediction = tf.argmax(model, 1)\n",
    "target = tf.argmax(Y, 1)\n",
    "print('예측값: ', sess.run(prediction, feed_dict={X: x_data}))\n",
    "print('실제값: ', sess.run(target, feed_dict={Y: y_data}))\n",
    "\n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_data, Y: y_data}))\n",
    "\n",
    "# 정확도: 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
