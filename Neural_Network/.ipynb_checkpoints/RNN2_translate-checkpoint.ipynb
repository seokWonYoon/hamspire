{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"챗봇, 번역, 이미지 캡쳐에 사용되는 Seq2Seq  모델 구현\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S 는 디코딩 입력의 시작을 나타내는 심볼\n",
    "# E 는 끝을 나타냄\n",
    "# P 는 현재 배치 데이터의 time step 크기보다 작은 경우 빈 시퀄스를 채우는 심볼\n",
    "\"\"\"\n",
    "예) 현재 배치 데이터의 최대 크기가 4인 경우\n",
    "word -> ['w', 'o', 'r', 'd']\n",
    "to -> ['t', 'o', 'P', 'P']\n",
    "\"\"\"\n",
    "char_arr = [c for c in 'SEPabcdefghijklmnopqrstuvwxyz단어나무놀이소녀키스사랑']  # 알파벳소문자\n",
    "num_dic = {n: i for i, n in enumerate(char_arr)}\n",
    "dic_len = len(num_dic)\n",
    "\n",
    "# 영어를 한글로 번역하기 위한 학습데이터\n",
    "seq_data = [['word', '단어'],['wood','나무'],\n",
    "            ['game', '놀이'],['girl', '소녀'],['kiss', '키스'],['love', '사랑']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(seq_data):\n",
    "    input_batch = []\n",
    "    output_batch = []\n",
    "    target_batch = []\n",
    "\n",
    "    for seq in seq_data:\n",
    "        # 인코더 셀의 입력값. 입력단어의 글자들을 한글자씩 떼어 배열로 만든다\n",
    "        input = [num_dic[n] for n in seq[0]]\n",
    "        # 디코더 셀의 입력값. 시작을 나타내는 S 심볼을 맨 앞에 붙인다\n",
    "        output = [num_dic[n] for n in ('S' + seq[1])]\n",
    "        target = [num_dic[n] for n in (seq[1] + 'E')]  #끝나는 지점 E\n",
    "\n",
    "        input_batch.append(np.eye(dic_len)[input])\n",
    "        output_batch.append(np.eye(dic_len)[output])\n",
    "        target_batch.append(target)\n",
    "    return input_batch, output_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *********\n",
    "# 옵션 설정\n",
    "# *********\n",
    "learning_rate = 0.01\n",
    "n_hidden = 128\n",
    "total_epoch = 100\n",
    "\n",
    "n_class = n_input = dic_len # 입력과 출력의 형태가 one-hot 인코딩으로 같으므로 크기도 동일함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-d616450070de>:10: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "# ********\n",
    "# 신경망 모델 구성\n",
    "# ********\n",
    "enc_input = tf.placeholder(tf.float32, [None, None, n_input]) # [배치사이즈, 타임스텝, 인풋사이즈]\n",
    "dec_input = tf.placeholder(tf.float32, [None, None, n_input])\n",
    "targets = tf.placeholder(tf.int64, [None, None]) #  [배치사이즈, 타임스텝]\n",
    "\n",
    "# 인코더 셀을 구성한다\n",
    "with tf.variable_scope('encode'):\n",
    "    enc_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "    enc_cell = tf.nn.rnn_cell.DropoutWrapper(enc_cell, output_keep_prob=0.5)\n",
    "    outputs, enc_states = tf.nn.dynamic_rnn(enc_cell, enc_input, dtype=tf.float32)\n",
    "\n",
    "# 디코더 셀을 구성한다\n",
    "with tf.variable_scope('decode'):\n",
    "    dec_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "    dec_cell = tf.nn.rnn_cell.DropoutWrapper(dec_cell, output_keep_prob=0.5)\n",
    "    outputs, dec_states = tf.nn.dynamic_rnn(dec_cell,dec_input, \n",
    "                                            initial_state=enc_states,dtype=tf.float32)\n",
    "\n",
    "model = tf.layers.dense(outputs, n_class, activation=None)\n",
    "cost = tf.reduce_mean(\n",
    "                      tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                          logits=model, labels=targets))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0001 cost = 3.678409\n",
      "Epoch:  0002 cost = 2.560664\n",
      "Epoch:  0003 cost = 1.589798\n",
      "Epoch:  0004 cost = 1.267077\n",
      "Epoch:  0005 cost = 0.631159\n",
      "Epoch:  0006 cost = 0.586109\n",
      "Epoch:  0007 cost = 0.180354\n",
      "Epoch:  0008 cost = 0.201056\n",
      "Epoch:  0009 cost = 0.305857\n",
      "Epoch:  0010 cost = 0.194725\n",
      "Epoch:  0011 cost = 0.087245\n",
      "Epoch:  0012 cost = 0.171708\n",
      "Epoch:  0013 cost = 0.085120\n",
      "Epoch:  0014 cost = 0.110539\n",
      "Epoch:  0015 cost = 0.137306\n",
      "Epoch:  0016 cost = 0.050225\n",
      "Epoch:  0017 cost = 0.239832\n",
      "Epoch:  0018 cost = 0.205266\n",
      "Epoch:  0019 cost = 0.054115\n",
      "Epoch:  0020 cost = 0.031957\n",
      "Epoch:  0021 cost = 0.035090\n",
      "Epoch:  0022 cost = 0.051150\n",
      "Epoch:  0023 cost = 0.015367\n",
      "Epoch:  0024 cost = 0.015688\n",
      "Epoch:  0025 cost = 0.002119\n",
      "Epoch:  0026 cost = 0.009464\n",
      "Epoch:  0027 cost = 0.001919\n",
      "Epoch:  0028 cost = 0.008552\n",
      "Epoch:  0029 cost = 0.006438\n",
      "Epoch:  0030 cost = 0.002160\n",
      "Epoch:  0031 cost = 0.003053\n",
      "Epoch:  0032 cost = 0.004374\n",
      "Epoch:  0033 cost = 0.004726\n",
      "Epoch:  0034 cost = 0.003360\n",
      "Epoch:  0035 cost = 0.005216\n",
      "Epoch:  0036 cost = 0.004184\n",
      "Epoch:  0037 cost = 0.001773\n",
      "Epoch:  0038 cost = 0.000827\n",
      "Epoch:  0039 cost = 0.002584\n",
      "Epoch:  0040 cost = 0.001324\n",
      "Epoch:  0041 cost = 0.001739\n",
      "Epoch:  0042 cost = 0.000868\n",
      "Epoch:  0043 cost = 0.002376\n",
      "Epoch:  0044 cost = 0.000972\n",
      "Epoch:  0045 cost = 0.001175\n",
      "Epoch:  0046 cost = 0.001784\n",
      "Epoch:  0047 cost = 0.002143\n",
      "Epoch:  0048 cost = 0.001764\n",
      "Epoch:  0049 cost = 0.001274\n",
      "Epoch:  0050 cost = 0.001854\n",
      "Epoch:  0051 cost = 0.000942\n",
      "Epoch:  0052 cost = 0.002351\n",
      "Epoch:  0053 cost = 0.000300\n",
      "Epoch:  0054 cost = 0.000640\n",
      "Epoch:  0055 cost = 0.000388\n",
      "Epoch:  0056 cost = 0.000524\n",
      "Epoch:  0057 cost = 0.000662\n",
      "Epoch:  0058 cost = 0.000474\n",
      "Epoch:  0059 cost = 0.000714\n",
      "Epoch:  0060 cost = 0.000314\n",
      "Epoch:  0061 cost = 0.001000\n",
      "Epoch:  0062 cost = 0.001100\n",
      "Epoch:  0063 cost = 0.000494\n",
      "Epoch:  0064 cost = 0.000703\n",
      "Epoch:  0065 cost = 0.000482\n",
      "Epoch:  0066 cost = 0.000691\n",
      "Epoch:  0067 cost = 0.000422\n",
      "Epoch:  0068 cost = 0.000817\n",
      "Epoch:  0069 cost = 0.000637\n",
      "Epoch:  0070 cost = 0.000468\n",
      "Epoch:  0071 cost = 0.001373\n",
      "Epoch:  0072 cost = 0.000938\n",
      "Epoch:  0073 cost = 0.001101\n",
      "Epoch:  0074 cost = 0.000837\n",
      "Epoch:  0075 cost = 0.000375\n",
      "Epoch:  0076 cost = 0.000979\n",
      "Epoch:  0077 cost = 0.000343\n",
      "Epoch:  0078 cost = 0.000395\n",
      "Epoch:  0079 cost = 0.000961\n",
      "Epoch:  0080 cost = 0.000873\n",
      "Epoch:  0081 cost = 0.000214\n",
      "Epoch:  0082 cost = 0.000555\n",
      "Epoch:  0083 cost = 0.000240\n",
      "Epoch:  0084 cost = 0.000706\n",
      "Epoch:  0085 cost = 0.002377\n",
      "Epoch:  0086 cost = 0.000607\n",
      "Epoch:  0087 cost = 0.000519\n",
      "Epoch:  0088 cost = 0.000596\n",
      "Epoch:  0089 cost = 0.000235\n",
      "Epoch:  0090 cost = 0.000086\n",
      "Epoch:  0091 cost = 0.000316\n",
      "Epoch:  0092 cost = 0.000366\n",
      "Epoch:  0093 cost = 0.000303\n",
      "Epoch:  0094 cost = 0.000249\n",
      "Epoch:  0095 cost = 0.000310\n",
      "Epoch:  0096 cost = 0.000750\n",
      "Epoch:  0097 cost = 0.000330\n",
      "Epoch:  0098 cost = 0.000864\n",
      "Epoch:  0099 cost = 0.000522\n",
      "Epoch:  0100 cost = 0.000310\n",
      "최적화 완료\n"
     ]
    }
   ],
   "source": [
    "# *****\n",
    "# 신경망 모델 학습\n",
    "# ****\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "input_batch, output_batch, target_batch = make_batch(seq_data)\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    _, loss = sess.run([optimizer, cost],feed_dict={\n",
    "        enc_input: input_batch,\n",
    "        dec_input: output_batch,\n",
    "        targets: target_batch})\n",
    "    print('Epoch: ','%04d'  % (epoch + 1),\n",
    "          'cost =', '{:.6f}'.format(loss))\n",
    "\n",
    "print('최적화 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====번역 테스트========\n",
      "word -> 단 어\n",
      "love -> 사 랑\n",
      "loev -> 사 랑\n",
      "girl -> 소 녀\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'E' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-0ef4254d440c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'loev ->'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'loev'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'girl ->'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'girl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'abcd ->'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'abcd'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-0ef4254d440c>\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m     11\u001b[0m                                  targets: target_batch})\n\u001b[0;32m     12\u001b[0m     \u001b[0mdecoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mchar_arr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'E'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mtranslated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtranslated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 'E' is not in list"
     ]
    }
   ],
   "source": [
    "# ********\n",
    "# 번역 테스트\n",
    "# *******\n",
    "def translate(word):\n",
    "    seq_data = [word, 'P' * len(word) ]\n",
    "    input_batch, output_batch, target_batch = make_batch([seq_data])\n",
    "    prediction = tf.argmax(model, 2)\n",
    "    result = sess.run(prediction,\n",
    "                      feed_dict={enc_input: input_batch,\n",
    "                                 dec_input: output_batch,\n",
    "                                 targets: target_batch})\n",
    "    decoded = [char_arr[i] for i in result[0]]\n",
    "    end = decoded.index('E')\n",
    "    translated = ' '.join(decoded[:end])\n",
    "    return translated\n",
    "\n",
    "print('=====번역 테스트========')\n",
    "print('word ->', translate('word'))\n",
    "print('love ->', translate('love'))\n",
    "print('loev ->', translate('loev'))\n",
    "print('girl ->', translate('girl'))\n",
    "print('abcd ->', translate('abcd'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
