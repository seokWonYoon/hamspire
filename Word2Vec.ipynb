{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc('font', family =font_manager.FontProperties(fname='C:/Windows/Fonts/H2GTRM.TTF').get_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"나 고양이 좋다\",\n",
    "            \"나 강아지 좋다\",\n",
    "            \"나 동물 좋다\",\n",
    "            \"강아지 고양이 동물\",\n",
    "            \"여자친구 고양이 강아지 좋다\",\n",
    "            \"고양이 생선 우유 좋다\",\n",
    "            \"강아지 생선 싫다 우유 좋다\",\n",
    "            \"강아지 고양이 눈 좋다\",\n",
    "            \"나 여자친구 좋다\",\n",
    "            \"여자친구 나 싫다\",\n",
    "            \"여자친구 나 영화 책 음악 좋다\",\n",
    "            \"나 게임 만화 애니 좋다\",\n",
    "            \"고양이 강아지 싫다\",\n",
    "            \"강아지 고양이 좋다\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 문장을 모두 합한 후 공백으로 단어들을 나누고 고유한 단어들로 리스트를 만듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['나',\n",
       " '고양이',\n",
       " '좋다',\n",
       " '나',\n",
       " '강아지',\n",
       " '좋다',\n",
       " '나',\n",
       " '동물',\n",
       " '좋다',\n",
       " '강아지',\n",
       " '고양이',\n",
       " '동물',\n",
       " '여자친구',\n",
       " '고양이',\n",
       " '강아지',\n",
       " '좋다',\n",
       " '고양이',\n",
       " '생선',\n",
       " '우유',\n",
       " '좋다',\n",
       " '강아지',\n",
       " '생선',\n",
       " '싫다',\n",
       " '우유',\n",
       " '좋다',\n",
       " '강아지',\n",
       " '고양이',\n",
       " '눈',\n",
       " '좋다',\n",
       " '나',\n",
       " '여자친구',\n",
       " '좋다',\n",
       " '여자친구',\n",
       " '나',\n",
       " '싫다',\n",
       " '여자친구',\n",
       " '나',\n",
       " '영화',\n",
       " '책',\n",
       " '음악',\n",
       " '좋다',\n",
       " '나',\n",
       " '게임',\n",
       " '만화',\n",
       " '애니',\n",
       " '좋다',\n",
       " '고양이',\n",
       " '강아지',\n",
       " '싫다',\n",
       " '강아지',\n",
       " '고양이',\n",
       " '좋다']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['눈',\n",
       " '애니',\n",
       " '생선',\n",
       " '영화',\n",
       " '여자친구',\n",
       " '게임',\n",
       " '동물',\n",
       " '고양이',\n",
       " '책',\n",
       " '좋다',\n",
       " '강아지',\n",
       " '싫다',\n",
       " '만화',\n",
       " '우유',\n",
       " '나',\n",
       " '음악']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_sequence = \" \".join(sentences).split()\n",
    "display(word_sequence)\n",
    "word_list = list(set(word_sequence))\n",
    "display(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {w: i for i, w in enumerate(word_list)}\n",
    "skip_grams = []\n",
    "# 윈도우 사이즈를 1 로 하는 skip-gram 모델을 만듭니다.\n",
    "# 예) 나 게임 만화 애니 좋다\n",
    "#   -> ([나, 만화], 게임), ([게임, 애니], 만화), ([만화, 좋다], 애니)\n",
    "#   -> (게임, 나), (게임, 만화), (만화, 게임), (만화, 애니), (애니, 만화), (애니, 좋다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(word_sequence)-1):\n",
    "    target = word_dict[word_sequence[i]]\n",
    "    context = [word_dict[word_sequence[i-1]], word_dict[word_sequence[i+1]]]\n",
    "    \n",
    "    for w in context :\n",
    "        skip_grams.append([target, w])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### skip_grams 데이터에서 무작위로 데이터를 뽑아 입력값과 출력값의 배치 데이터를 생성하는 함수\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(data, size):\n",
    "    random_inputs = []\n",
    "    random_labels = []\n",
    "    random_index = np.random.choice(range(len(data)), size, replace=False)\n",
    "    \n",
    "    for i in random_index:\n",
    "        random_inputs.append(data[i][0]) #target\n",
    "        random_labels.append(data[i][1]) # context word\n",
    "        return random_inputs, random_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵션설정\n",
    "training_epoch = 300 # 학습을 반복할 횟수\n",
    "learning_rate = 0.1 # 학습률\n",
    "batch_size = 20 # 한번에 학습할 데이터의 크기\n",
    "embedding_size = 2 #단어 벡터를 구성할 임베딩 차원의 크기, x,y 두개면 2\n",
    "num_sampled = 15 # 학습함수인 nce_loss에서 사용하는 샘플링크기\n",
    "# num_sampled 는 batch_size 보다 작아야한다.\n",
    "voc_size = len(word_list) # 총단어의 갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *******\n",
    "# 신경망 모델 구성\n",
    "# *******\n",
    "inputs = tf.placeholder(tf.float32, shape=[batch_size])\n",
    "labels = tf.placeholder(tf.float32, shape=[batch_size, 1])\n",
    "# shape = [batch_size, 1]는 텐서학습함수인 tf.nn.nce_loss를 사용하기 위한 출력값 세팅\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word2vec 모델의 결과값인 임베딩벡터를 저장할 변수\n",
    "총 단어의 갯수와 임배딩 갯수를 크기로 하는 두개의 차원을 보유함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = tf.Variable(tf.random_uniform([voc_size, embedding_size], -1.0, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임베딩 벡터의 예제\n",
    "\n",
    "##### 임베딩 벡터의 차원에서 학습할 입력값에 대한 행들을 뽑아옵니다.\n",
    "##### 예) embeddings     inputs    selected\n",
    "#####    [[1, 2, 3]  -> [2, 3] -> [[2, 3, 4]\n",
    "#####     [2, 3, 4]                [3, 4, 5]]\n",
    "#####     [3, 4, 5]\n",
    "#####     [4, 5, 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Value passed to parameter 'indices' has DataType float32 not in list of allowed values: int32, int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mgather\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   2672\u001b[0m     \u001b[1;31m# introducing a circular dependency.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2673\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2674\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'sparse_read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-b80cc3f950c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mselected_embed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_lookup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\embedding_ops.py\u001b[0m in \u001b[0;36membedding_lookup\u001b[1;34m(params, ids, partition_strategy, name, validate_indices, max_norm)\u001b[0m\n\u001b[0;32m    311\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m       \u001b[0mmax_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m       transform_fn=None)\n\u001b[0m\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\embedding_ops.py\u001b[0m in \u001b[0;36m_embedding_lookup_and_transform\u001b[1;34m(params, ids, partition_strategy, name, max_norm, transform_fn)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mtransform_fn\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m         result = _clip(array_ops.gather(params[0], ids, name=name),\n\u001b[0m\u001b[0;32m    134\u001b[0m                        ids, max_norm)\n\u001b[0;32m    135\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtransform_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mgather\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   2673\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mgather_v2\u001b[1;34m(params, indices, axis, name)\u001b[0m\n\u001b[0;32m   3329\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3330\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 3331\u001b[1;33m         \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n\u001b[0m\u001b[0;32m   3332\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3333\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    607\u001b[0m               _SatisfiesTypeConstraint(base_type,\n\u001b[0;32m    608\u001b[0m                                        \u001b[0m_Attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 609\u001b[1;33m                                        param_name=input_name)\n\u001b[0m\u001b[0;32m    610\u001b[0m             \u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m             \u001b[0minferred_from\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_SatisfiesTypeConstraint\u001b[1;34m(dtype, attr_def, param_name)\u001b[0m\n\u001b[0;32m     58\u001b[0m           \u001b[1;34m\"allowed values: %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m           (param_name, dtypes.as_dtype(dtype).name,\n\u001b[1;32m---> 60\u001b[1;33m            \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Value passed to parameter 'indices' has DataType float32 not in list of allowed values: int32, int64"
     ]
    }
   ],
   "source": [
    "selected_embed = tf.nn.embedding_lookup(embeddings, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Value passed to parameter 'indices' has DataType float32 not in list of allowed values: int32, int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mgather\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   2672\u001b[0m     \u001b[1;31m# introducing a circular dependency.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2673\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2674\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'sparse_read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-b80cc3f950c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mselected_embed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_lookup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\embedding_ops.py\u001b[0m in \u001b[0;36membedding_lookup\u001b[1;34m(params, ids, partition_strategy, name, validate_indices, max_norm)\u001b[0m\n\u001b[0;32m    311\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m       \u001b[0mmax_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m       transform_fn=None)\n\u001b[0m\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\embedding_ops.py\u001b[0m in \u001b[0;36m_embedding_lookup_and_transform\u001b[1;34m(params, ids, partition_strategy, name, max_norm, transform_fn)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mtransform_fn\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m         result = _clip(array_ops.gather(params[0], ids, name=name),\n\u001b[0m\u001b[0;32m    134\u001b[0m                        ids, max_norm)\n\u001b[0;32m    135\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtransform_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mgather\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   2673\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mgather_v2\u001b[1;34m(params, indices, axis, name)\u001b[0m\n\u001b[0;32m   3329\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3330\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 3331\u001b[1;33m         \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n\u001b[0m\u001b[0;32m   3332\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3333\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    607\u001b[0m               _SatisfiesTypeConstraint(base_type,\n\u001b[0;32m    608\u001b[0m                                        \u001b[0m_Attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 609\u001b[1;33m                                        param_name=input_name)\n\u001b[0m\u001b[0;32m    610\u001b[0m             \u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m             \u001b[0minferred_from\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_SatisfiesTypeConstraint\u001b[1;34m(dtype, attr_def, param_name)\u001b[0m\n\u001b[0;32m     58\u001b[0m           \u001b[1;34m\"allowed values: %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m           (param_name, dtypes.as_dtype(dtype).name,\n\u001b[1;32m---> 60\u001b[1;33m            \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Value passed to parameter 'indices' has DataType float32 not in list of allowed values: int32, int64"
     ]
    }
   ],
   "source": [
    "# nce_loss 에서 사용할 변수 정의\n",
    "nce_weights = tf.Variable(tf.random_uniform([voc_size, embedding_size], -1.0, 1.0))\n",
    "nce_biases = tf.Variable(tf.zeros([voc_size]))\n",
    "\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.nce_loss(nce_weights, nce_biases, labels, selected_embed, num_sampled, voc_size)\n",
    "    )\n",
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# ****\n",
    "# 신경망 모델 학습\n",
    "# ****\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, training_epoch + 1):\n",
    "        batch_inputs, batch_labels = random_batch(skip_grams, batch_size)\n",
    "        _, loss_val = sess.run([train_op, loss],\n",
    "                               feed_dict={inputs: batch_inputs,\n",
    "                                          labels: batch_labels})\n",
    "        if step % 10 == 0:\n",
    "            print(\"loss at step \", step, \" : \", loss_val)\n",
    "    trained_embeddings = embeddings.eval()\n",
    "    \n",
    "# ****\n",
    "# 임베딩된 word2vec 결과 확인\n",
    "# ****\n",
    "for i, label in enumerate(word_list):\n",
    "    x,  y = trained_embeddings[i]\n",
    "    plt.scatter(x,y)\n",
    "    plt.annotate(label, xy=(x, y), xytext=(5,2),\n",
    "                 textcoords='offset points', ha='right', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Value passed to parameter 'indices' has DataType float32 not in list of allowed values: int32, int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mgather\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   2672\u001b[0m     \u001b[1;31m# introducing a circular dependency.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2673\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2674\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'sparse_read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-ecec7e552c93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mselected_embed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_lookup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# nce_loss 에서 사용할 변수 정의\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnce_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvoc_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnce_biases\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvoc_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\embedding_ops.py\u001b[0m in \u001b[0;36membedding_lookup\u001b[1;34m(params, ids, partition_strategy, name, validate_indices, max_norm)\u001b[0m\n\u001b[0;32m    311\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m       \u001b[0mmax_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m       transform_fn=None)\n\u001b[0m\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\embedding_ops.py\u001b[0m in \u001b[0;36m_embedding_lookup_and_transform\u001b[1;34m(params, ids, partition_strategy, name, max_norm, transform_fn)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mtransform_fn\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m         result = _clip(array_ops.gather(params[0], ids, name=name),\n\u001b[0m\u001b[0;32m    134\u001b[0m                        ids, max_norm)\n\u001b[0;32m    135\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtransform_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mgather\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   2673\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mgather_v2\u001b[1;34m(params, indices, axis, name)\u001b[0m\n\u001b[0;32m   3329\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3330\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 3331\u001b[1;33m         \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n\u001b[0m\u001b[0;32m   3332\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3333\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    607\u001b[0m               _SatisfiesTypeConstraint(base_type,\n\u001b[0;32m    608\u001b[0m                                        \u001b[0m_Attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 609\u001b[1;33m                                        param_name=input_name)\n\u001b[0m\u001b[0;32m    610\u001b[0m             \u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m             \u001b[0minferred_from\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_SatisfiesTypeConstraint\u001b[1;34m(dtype, attr_def, param_name)\u001b[0m\n\u001b[0;32m     58\u001b[0m           \u001b[1;34m\"allowed values: %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m           (param_name, dtypes.as_dtype(dtype).name,\n\u001b[1;32m---> 60\u001b[1;33m            \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Value passed to parameter 'indices' has DataType float32 not in list of allowed values: int32, int64"
     ]
    }
   ],
   "source": [
    "# nce_loss 에서 사용할 변수 정의\n",
    "nce_weights = tf.Variable(tf.random_uniform([voc_size, embedding_size], -1.0, 1.0))\n",
    "nce_biases = tf.Variable(tf.zeros[voc_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Value passed to parameter 'indices' has DataType float32 not in list of allowed values: int32, int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mgather\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   2672\u001b[0m     \u001b[1;31m# introducing a circular dependency.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2673\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2674\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'sparse_read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-13f4e11606ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mselected_embed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_lookup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# nce_loss 에서 사용할 변수 정의\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnce_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvoc_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnce_biases\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvoc_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\embedding_ops.py\u001b[0m in \u001b[0;36membedding_lookup\u001b[1;34m(params, ids, partition_strategy, name, validate_indices, max_norm)\u001b[0m\n\u001b[0;32m    311\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m       \u001b[0mmax_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m       transform_fn=None)\n\u001b[0m\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\embedding_ops.py\u001b[0m in \u001b[0;36m_embedding_lookup_and_transform\u001b[1;34m(params, ids, partition_strategy, name, max_norm, transform_fn)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mtransform_fn\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m         result = _clip(array_ops.gather(params[0], ids, name=name),\n\u001b[0m\u001b[0;32m    134\u001b[0m                        ids, max_norm)\n\u001b[0;32m    135\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtransform_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mgather\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   2673\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mgather_v2\u001b[1;34m(params, indices, axis, name)\u001b[0m\n\u001b[0;32m   3329\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3330\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 3331\u001b[1;33m         \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n\u001b[0m\u001b[0;32m   3332\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3333\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    607\u001b[0m               _SatisfiesTypeConstraint(base_type,\n\u001b[0;32m    608\u001b[0m                                        \u001b[0m_Attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 609\u001b[1;33m                                        param_name=input_name)\n\u001b[0m\u001b[0;32m    610\u001b[0m             \u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m             \u001b[0minferred_from\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_SatisfiesTypeConstraint\u001b[1;34m(dtype, attr_def, param_name)\u001b[0m\n\u001b[0;32m     58\u001b[0m           \u001b[1;34m\"allowed values: %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m           (param_name, dtypes.as_dtype(dtype).name,\n\u001b[1;32m---> 60\u001b[1;33m            \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Value passed to parameter 'indices' has DataType float32 not in list of allowed values: int32, int64"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(\n",
    "    tf.nn.nce_loss(nce_weights, nce_biases, labels, selected_embed, num_sampled, voc_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *******\n",
    "# 신경망 모델 학습\n",
    "# *******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(1, training_epoch +1 ):\n",
    "        batch_inputs, batch_labels = random_batch(skip_grams, batch_size)\n",
    "        _, loss_val = sess.run([train_op, loss], feed_dict = {inputs:batch_inputs, lables:batch_labels})\n",
    "        if step % 10 ==10:\n",
    "            print(\"loss at step \", step,\":\",loss_val)\n",
    "    trained_embeddings = embeddings.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *******\n",
    "# 임베딩 된 word2vec 결과 확인\n",
    "# *******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, label in enumerate(word_list):\n",
    "    x, y = training_embeddings[i]\n",
    "    plt.scatter(x,y)\n",
    "    plt.annotate(label, xy = (x,y), xytext=(5,2), textcoords = 'offset points', ha='right', va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import font_manager, rc\n",
    "rc('font', family=font_manager.FontProperties(fname='C:/Windows/Fonts/malgun.ttf').get_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 설정 되어있는 폰트 사이즈\n",
      "10.0\n",
      "# 설정 되어있는 폰트 글꼴\n",
      "['Malgun Gothic']\n"
     ]
    }
   ],
   "source": [
    "# size, family\n",
    "print('# 설정 되어있는 폰트 사이즈')\n",
    "print (plt.rcParams['font.size'] ) \n",
    "print('# 설정 되어있는 폰트 글꼴')\n",
    "print (plt.rcParams['font.family'] )\n",
    "\n",
    "sentences = [\"나 고양이 좋다\",\n",
    "            \"나 강아지 좋다\",\n",
    "            \"나 동물 좋다\",\n",
    "            \"강아지 고양이 동물\",\n",
    "            \"여자친구 고양이 강아지 좋다\",\n",
    "            \"고양이 생선 우유 좋다\",\n",
    "            \"강아지 생선 싫다 우유 좋다\",\n",
    "            \"강아지 고양이 눈 좋다\",\n",
    "            \"나 여자친구 좋다\",\n",
    "            \"여자친구 나 싫다\",\n",
    "            \"여자친구 나 영화 책 음악 좋다\",\n",
    "            \"나 게임 만화 애니 좋다\",\n",
    "            \"고양이 강아지 싫다\",\n",
    "            \"강아지 고양이 좋다\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장을 모두 합한 후 공백으로 단어들을 나누고 고유한 단어들로 리스트를 만듬\n",
    "word_sequence = \" \".join(sentences).split()\n",
    "word_sequence \n",
    "word_list = list(set(word_sequence))\n",
    "word_list\n",
    "# 리스트에서 문자열의 인덱스를 뽑아서 사용해야함.\n",
    "# 이를 표현하기 위한 연관배열과 단어 리스트에서 단어를 참조할 수 있는\n",
    "# 인덱스 배열을 만듦\n",
    "\n",
    "word_dict = {w: i for i, w in enumerate(word_list)}\n",
    "\n",
    "skip_grams = []\n",
    "# 윈도우 사이즈를 1 로 하는 skip-gram 모델을 만듭니다.\n",
    "# 예) 나 게임 만화 애니 좋다\n",
    "#   -> ([나, 만화], 게임), ([게임, 애니], 만화), ([만화, 좋다], 애니)\n",
    "#   -> (게임, 나), (게임, 만화), (만화, 게임), (만화, 애니), (애니, 만화), (애니, 좋다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(word_sequence) -1):\n",
    "    target = word_dict[word_sequence[i]]\n",
    "    context = [word_dict[word_sequence[i -1]], word_dict[word_sequence[i +1]]]\n",
    "\n",
    "    for w in context:\n",
    "        skip_grams.append([target, w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip_grams 데이터에서 무작위로 데이터를 뽑아 입력값과 출력값의 배치 데이터를\n",
    "# 생성하는 함수\n",
    "\n",
    "def random_batch(data, size):\n",
    "    random_inputs = []\n",
    "    random_labels = []\n",
    "    random_index = np.random.choice(range(len(data)), size, replace=False)\n",
    "\n",
    "    for i in random_index:\n",
    "        random_inputs.append(data[i][0]) # target\n",
    "        random_labels.append([data[i][1]]) # context word\n",
    "    \n",
    "    return random_inputs, random_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵션 설정\n",
    "training_epoch = 300  # 학습을 반복할 횟수\n",
    "learning_rate = 0.1 # 학습률\n",
    "batch_size = 20  # 한번에 학습할 데이터의 크기\n",
    "embedding_size = 2 # 단어 벡터를 구성할 임베딩 차원의 크기, x, y 두개면 2\n",
    "num_sampled = 15 # 학습함수인 nce_loss 에서 사용하는 샘플링 크기\n",
    "\"\"\"num_sampled 는 batch_size 보다는 작아야 한다\"\"\"\n",
    "voc_size = len(word_list) # 총단어의 갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *********\n",
    "# 신경망 모델 구성\n",
    "# ********\n",
    "inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "#  shape=[batch_size, 1] 는 텐서 학습함수인 tf.nn.nce_loss 를 사용하기 위한 출력값 세팅\n",
    "\n",
    "\"\"\"word2vec 모델의 결과 값인 임베딩 벡터를 저장할 변수\n",
    "총단어 갯수와 임베딩갯수를 크기로 하는 두개의 차원을 보유함\n",
    "\"\"\"\n",
    "embeddings = tf.Variable(tf.random_uniform([voc_size, embedding_size], -1.0, 1.0))\n",
    "\n",
    "# 임베딩 벡터의 예제\n",
    "# 임베딩 벡터의 차원에서 학습할 입력값에 대한 행들을 뽑아옵니다.\n",
    "# 예) embeddings     inputs    selected\n",
    "#    [[1, 2, 3]  -> [2, 3] -> [[2, 3, 4]\n",
    "#     [2, 3, 4]                [3, 4, 5]]\n",
    "#     [3, 4, 5]\n",
    "#     [4, 5, 6]]\n",
    "\n",
    "selected_embed = tf.nn.embedding_lookup(embeddings, inputs)\n",
    "# nce_loss 에서 사용할 변수 정의\n",
    "nce_weights = tf.Variable(tf.random_uniform([voc_size, embedding_size], -1.0, 1.0))\n",
    "nce_biases = tf.Variable(tf.zeros([voc_size]))\n",
    "\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.nce_loss(nce_weights, nce_biases, labels, selected_embed, num_sampled, voc_size)\n",
    "    )\n",
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at step  10  :  5.56755\n",
      "loss at step  20  :  3.8136852\n",
      "loss at step  30  :  3.5117927\n",
      "loss at step  40  :  3.1870527\n",
      "loss at step  50  :  3.2817345\n",
      "loss at step  60  :  3.110017\n",
      "loss at step  70  :  3.2325833\n",
      "loss at step  80  :  3.114804\n",
      "loss at step  90  :  3.2438602\n",
      "loss at step  100  :  3.2567964\n",
      "loss at step  110  :  3.387162\n",
      "loss at step  120  :  2.7867513\n",
      "loss at step  130  :  3.12302\n",
      "loss at step  140  :  3.010732\n",
      "loss at step  150  :  3.163035\n",
      "loss at step  160  :  3.034853\n",
      "loss at step  170  :  3.4787102\n",
      "loss at step  180  :  3.0282512\n",
      "loss at step  190  :  3.2308984\n",
      "loss at step  200  :  2.9388108\n",
      "loss at step  210  :  2.919811\n",
      "loss at step  220  :  3.0849063\n",
      "loss at step  230  :  3.1308894\n",
      "loss at step  240  :  3.1289017\n",
      "loss at step  250  :  3.1596591\n",
      "loss at step  260  :  3.112617\n",
      "loss at step  270  :  3.0072434\n",
      "loss at step  280  :  3.096608\n",
      "loss at step  290  :  2.9458408\n",
      "loss at step  300  :  3.284059\n"
     ]
    }
   ],
   "source": [
    "# ****\n",
    "# 신경망 모델 학습\n",
    "# ****\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, training_epoch + 1):\n",
    "        batch_inputs, batch_labels = random_batch(skip_grams, batch_size)\n",
    "        _, loss_val = sess.run([train_op, loss],\n",
    "                               feed_dict={inputs: batch_inputs,\n",
    "                                          labels: batch_labels})\n",
    "        if step % 10 == 0:\n",
    "            print(\"loss at step \", step, \" : \", loss_val)\n",
    "    trained_embeddings = embeddings.eval()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ****\n",
    "# 임베딩된 word2vec 결과 확인\n",
    "# ****\n",
    "for i, label in enumerate(word_list):\n",
    "    x,  y = trained_embeddings[i]\n",
    "    plt.scatter(x,y)\n",
    "    plt.annotate(label, xy=(x, y), xytext=(5,2),\n",
    "                 textcoords='offset points', ha='right', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
